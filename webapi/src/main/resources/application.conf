akka {
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    loglevel = "INFO"
    stdout-loglevel = "INFO"
    logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
    log-dead-letters = off
    log-dead-letters-during-shutdown = off

    http {
        server {
            # The requested maximum length of the queue of incoming connections.
            # If the server is busy and the backlog is full the OS will start dropping
            # SYN-packets and connection attempts may fail. Note, that the backlog
            # size is usually only a maximum size hint for the OS and the OS can
            # restrict the number further based on global limits.
            backlog = 2048

            # The time after which an idle connection will be automatically closed.
            # Set to `infinite` to completely disable idle connection timeouts.
            idle-timeout = 380 s

            # Defines the default time period within which the application has to
            # produce an HttpResponse for any given HttpRequest it received.
            # The timeout begins to run when the *end* of the request has been
            # received, so even potentially long uploads can have a short timeout.
            # Set to `infinite` to completely disable request timeout checking.
            #
            # If this setting is not `infinite` the HTTP server layer attaches a
            # `Timeout-Access` header to the request, which enables programmatic
            # customization of the timeout period and timeout response for each
            # request individually.
            request-timeout = 360 s

            parsing {
                max-content-length = 110M
            }
        }

        client {
            # The time period within which the TCP connecting process must be completed.
            connecting-timeout = 10 s

            # The time after which an idle connection will be automatically closed.
            # Set to `infinite` to completely disable idle timeouts.
            idle-timeout = infinite

            parsing {
                max-chunk-size             = 8m
                max-response-reason-length = 1024
            }
        }

        host-connection-pool {
            # The maximum number of parallel connections that a connection pool to a
            # single host endpoint is allowed to establish. Must be greater than zero.
            max-connections = 1024

            # The minimum number of parallel connections that a pool should keep alive ("hot").
            # If the number of connections is falling below the given threshold, new ones are being spawned.
            # You can use this setting to build a hot pool of "always on" connections.
            # Default is 0, meaning there might be no active connection at given moment.
            # Keep in mind that `min-connections` should be smaller than `max-connections` or equal
            min-connections = 0

            # The maximum number of times failed requests are attempted again,
            # (if the request can be safely retried) before giving up and returning an error.
            # Set to zero to completely disable request retries.
            max-retries = 0

            # The maximum number of open requests accepted into the pool across all
            # materializations of any of its client flows.
            # Protects against (accidentally) overloading a single pool with too many client flow materializations.
            # Note that with N concurrent materializations the max number of open request in the pool
            # will never exceed N * max-connections * pipelining-limit.
            # Must be a power of 2 and > 0!
            max-open-requests = 2048

            # The maximum number of requests that are dispatched to the target host in
            # batch-mode across a single connection (HTTP pipelining).
            # A setting of 1 disables HTTP pipelining, since only one request per
            # connection can be "in flight" at any time.
            # Set to higher values to enable HTTP pipelining.
            # This value must be > 0.
            # (Note that, independently of this setting, pipelining will never be done
            # on a connection that still has a non-idempotent request in flight.
            #
            # Before increasing this value, make sure you understand the effects of head-of-line blocking.
            # Using a connection pool, a request may be issued on a connection where a previous
            # long-running request hasn't finished yet. The response to the pipelined requests may then be stuck
            # behind the response of the long-running previous requests on the server. This may introduce an
            # unwanted "coupling" of run time between otherwise unrelated requests.
            #
            # See http://tools.ietf.org/html/rfc7230#section-6.3.2 for more info.)
            pipelining-limit = 2

            # Modify to tweak client settings for host connection pools only.
            #
            # IMPORTANT:
            # Please note that this section mirrors `akka.http.client` however is used only for pool-based APIs,
            # such as `Http().superPool` or `Http().singleRequest`.
            client = {

                # The time period within which the TCP connecting process must be completed.
                connecting-timeout = 10s

                # The time after which an idle connection will be automatically closed.
                # Set to `infinite` to completely disable idle timeouts.
                idle-timeout = infinite
            }
        }
    }

    actor {
        deployment {
            user/storeManager/triplestoreManager/httpTriplestoreRouter {
                router = round-robin-pool
                nr-of-instances = 100
            }

            user/responderManager/resourcesRouter {
                router = round-robin-pool
                nr-of-instances = 50
            }

            user/responderManager/valuesRouter {
                router = round-robin-pool
                nr-of-instances = 20
            }

            user/responderManager/sipiRouter {
                router = round-robin-pool
                nr-of-instances = 50
            }

            user/responderManager/standoffRouter {
              router = round-robin-pool
              nr-of-instances = 50
            }

            user/responderManager/listsRouter {
                router = round-robin-pool
                nr-of-instances = 50
            }

            user/responderManager/usersRouter {
                router = round-robin-pool
                nr-of-instances = 50
            }

            user/responderManager/hierarchicalListsRouter {
                router = round-robin-pool
                nr-of-instances = 50
            }

            user/responderManager/searchRouter {
                router = round-robin-pool
                nr-of-instances = 50
            }

            user/responderManager/ontologyRouter {
                router = round-robin-pool
                nr-of-instances = 50
            }

            user/responderManager/projectsRouter {
                router = round-robin-pool
                nr-of-instances = 20
            }

            user/responderManager/ckanRouter {
                router = round-robin-pool
                nr-of-instances = 5
            }

            user/responderManager/storeRouter {
                router = round-robin-pool
                nr-of-instances = 1
            }

            user/responderManager/permissionsRouter {
                router = round-robin-pool
                nr-of-instances = 20
            }

            user/responderManager/groupsRouter {
                router = round-robin-pool
                nr-of-instances = 20
            }
        }
    }
}

app {

    default-timeout = 60 // seconds

    default-restore-timeout = 360 // seconds

    // If true, log all messages sent from and received by routes. Since messages are logged at DEBUG level, you will
    // need to set loglevel = "DEBUG" in the akka section of this file, and <root level="DEBUG"> in logback.xml.
    dump-messages = false

    show-internal-errors = true // If true, clients will see error messages from internal errors. Useful for debugging. If false, those error messages will appear only in the log.

    skip-authentication = false // If true, the authentication process is skiped and the Lothar Schmidt user is returned by default.

    // Using the assets route. Works only for read access and only a few images.
    sipi {
        url = "http://localhost"
        port = 1024
        prefix = "knora"
        file-server-path = "server"
        path-conversion-route = "convert_from_binaries"
        file-conversion-route = "convert_from_file"
        image-mime-types = ["image/tiff", "image/jpeg", "image/png", "image/jp2"]
        movie-mime-types = []
        sound-mime-types = []
    }

//    sipi {
//        url = "http://localhost"
//        path = ""
//        port = 1024
//        path-conversion-route = "convert_path"
//        file-conversion-route = "convert_file"
//        image-mime-types = ["image/tiff", "image/jpeg", "image/png", "image/jp2"]
//        movie-mime-types = []
//        sound-mime-types = []
//    }

    http {
        https {
            keystore = "https/localhost.jks"
            keystore-password = "test keystore password"
        }

        knora-api {
            host = "0.0.0.0"
            http-port = 3333
            https-port = 3334
            use-http = true
            use-https = false
        }

        salsah {
            base-url = "http://localhost:3335/"
            project-icons-basepath = "project-icons/"
        }
    }

    caches = [
        {
            cache-name = "ontologyCache"
            max-elements-in-memory = 0
            overflow-to-disk = false
            eternal = true
            time-to-live-seconds = 0
            time-to-idle-seconds = 0
        },
        {
            cache-name = "authenticationCache"
            max-elements-in-memory = 0
            overflow-to-disk = false
            eternal = true
            time-to-live-seconds = 600
            time-to-idle-seconds = 0
        },
        {
            cache-name = "mappingCache"
            max-elements-in-memory = 0
            overflow-to-disk = false
            eternal = true
            time-to-live-seconds = 600
            time-to-idle-seconds = 0
        }

    ]

    tmp-datadir = "/tmp/webapi_tmp/" // dir must exist on disk!
    datadir = "/tmp/webapi/" // dir must exist on disk!

    max-results-per-search-result-page = 500

    gui {
        // The default size of resource type icons. TODO: put icon sizes in the triplestore instead.
        default-icon-size {
            dimX = 32
            dimY = 32
        }
    }

    triplestore {
        dbtype = "fuseki"
        // dbtype = "graphdb"
        // dbtype = "embedded-jena-tdb"
        // dbtype = "sesame"
        // dbtype = "embedded-jena-graphdb"
        // dbtype = "fake-triplestore"

        host = "localhost"

        graphdb {
            port = 7200
            repository-name = "knora-test"
            username = "admin"
            password = "root"
        }

        sesame {
            port = 8080
            repository-name = "knora-test"
        }

        fuseki {
            port = 3030
            repository-name = "knora-test"
            tomcat = false
            tomcat-context = ""
        }

        embedded-jena-tdb {
            persisted = true // "false" -> memory, "true" -> disk
            loadExistingData = false // "false" -> use data if exists, "false" -> create a fresh store
            storage-path = "_TMP" // ignored if "memory"
        }

        embedded-jena-graphdb {
            graphdb-persisted-storage = true
            graphdb-storage-path = "_TMP_GRAPHDB"
        }

        fake-jena-tdb {
            fake-persisted-storage = true
            fake-triplestore-data-dir = "src/main/resources/query-log"
        }

        reload-on-start = false // ignored if "memory" as it will always reload

        default-rdf-data = [ // this data is always loaded during resetting of the triple store content
            {
                path = "../knora-ontologies/knora-base.ttl"
                name = "http://www.knora.org/ontology/knora-base"
            }
            {
                path = "../knora-ontologies/knora-admin.ttl"
                name = "http://www.knora.org/ontology/knora-base"
            }
            {
                path = "../knora-ontologies/standoff-onto.ttl"
                name = "http://www.knora.org/ontology/standoff"
            }
            {
                path = "../knora-ontologies/standoff-data.ttl"
                name = "http://www.knora.org/data/standoff"
            }
            {
                path = "../knora-ontologies/knora-dc.ttl"
                name = "http://www.knora.org/ontology/dc"
            }
            {
                path = "../knora-ontologies/salsah-gui.ttl"
                name = "http://www.knora.org/ontology/salsah-gui"
            }
            {
                path = "_test_data/all_data/admin-data.ttl"
                name = "http://www.knora.org/data/admin"
            }
            {
                path = "_test_data/all_data/permissions-data.ttl"
                name = "http://www.knora.org/data/permissions"
            }
            {
                path = "_test_data/ontologies/anything-onto.ttl"
                name = "http://www.knora.org/ontology/anything"
            }
            {
                path = "_test_data/ontologies/beol-onto.ttl"
                name = "http://www.knora.org/ontology/beol"
            }
            {
                path = "_test_data/ontologies/biblio-onto.ttl"
                name = "http://www.knora.org/ontology/biblio"
            }
            {
                path = "_test_data/ontologies/dokubib-onto.ttl"
                name = "http://www.knora.org/ontology/dokubib"
            }
            {
                path = "_test_data/ontologies/images-onto.ttl"
                name = "http://www.knora.org/ontology/images"
            }
            {
                path = "_test_data/ontologies/incunabula-onto.ttl"
                name = "http://www.knora.org/ontology/incunabula"
            }
        ]

        rdf-data = [
            {
                path = "_test_data/ontologies/incunabula-onto.ttl"
                name = "http://www.knora.org/ontology/incunabula"
            }
            {
                path = "_test_data/demo_data/incunabula-demo-data.ttl"
                name = "http://www.knora.org/data/incunabula"
            }
            {
                path = "_test_data/ontologies/images-onto.ttl"
                name = "http://www.knora.org/ontology/dokubib"
            }
            {
                path = "_test_data/demo_data/images-demo-data.ttl"
                name = "http://www.knora.org/data/dokubib"
            }
            {
                path = "_test_data/ontologies/anything-onto.ttl"
                name = "http://www.knora.org/ontology/anything"
            }
            {
                path = "_test_data/all_data/anything-data.ttl"
                name = "http://www.knora.org/data/anything"
            }
            {
                path = "_test_data/ontologies/beol-onto.ttl"
                name = "http://www.knora.org/ontology/beol"
            }
            {
                path = "_test_data/all_data/beol-data.ttl"
                name = "http://www.knora.org/data/beol"
            }
            {
                path = "_test_data/ontologies/biblio-onto.ttl"
                name = "http://www.knora.org/ontology/biblio"
            }
            {
                path = "_test_data/all_data/biblio-data.ttl"
                name = "http://www.knora.org/data/biblio"
            }

        ]

        // If true, the time taken by each SPARQL query is logged at DEBUG level. To see these messages,
        // set loglevel = "DEBUG" above, and
        // <logger name="org.knora.webapi.store.triplestore.http.HttpTriplestoreConnector" level="DEBUG"/>
        // in logback.xml.
        profile-queries = false

        ///////////////////////////////////////////////////////////////////////////////////////////////////////////////
        // Fake triplestore settings
        //
        // The application can generate a fake triplestore, consisting of SPARQL queries and responses saved in
        // text files (in fake-triplestore-query-dir). This is useful for:
        //
        // * measuring the response time of the application minus the response time of the triplestore.
        //
        // * debugging SPARQL queries, because you can open the generated queries in a text editor and copy and paste
        //   them into something like GraphDB Workbench to experiment with them.
        //
        // * benchmarking triplestores, because you can feed the whole fake triplestore file structure to RDFBench.
        //
        // To generate a fake triplestore, set fake-triplestore to "prepare", start the application, and run one or more
        // API operations. The fake triplestore will contain all the SPARQL queries and responses involved in those
        // operations.
        //
        // To have the application use the fake triplestore, set fake-triplestore to "use", and restart the application.
        // The entire contents of the fake triplestore will be loaded when the application starts, and all SPARQL queries
        // will simply be hashtable lookups in this in-memory data.
        //
        // To just use a real triplestore, set fake-triplestore to "off".
        fake-triplestore = "off"
        fake-triplestore-data-dir = "src/main/resources/query-log"
    }

}

user {
    default-language: "en"
}

//kamon.metric.tick-interval = 1 second
//
//kamon.modules {
//    kamon-statsd.auto-start = false
//    kamon-log-reporter.auto-start = false
//}
//
//kamon.metric.filters {
//    akka-actor {
//        includes = ["**"]
//        excludes = []
//    }
//    akka-router {
//        includes = ["**"]
//        excludes = []
//    }
//    akka-dispatcher {
//        includes = ["**"]
//        excludes = []
//    }
//    trace {
//        includes = ["**"]
//        excludes = []
//    }
//}
//
//kamon.akka.ask-pattern-timeout-warning = "lightweight"
//
//kamon.statsd {
//    # Hostname and port in which your StatsD is running. Remember that StatsD packets are sent using UDP and
//    # setting unreachable hosts and/or not open ports wont be warned by the Kamon, your data wont go anywhere.
//    hostname = "192.168.59.103"
//    port = 8125
//
//    # Interval between metrics data flushes to StatsD. It's value must be equal or greater than the
//    # kamon.metric.tick-interval setting.
//    flush-interval = 1 second
//
//    # Max packet size for UDP metrics data sent to StatsD.
//    max-packet-size = 1024 bytes
//
//    # Subscription patterns used to select which metrics will be pushed to StatsD. Note that first, metrics
//    # collection for your desired entities must be activated under the kamon.metrics.filters settings.
//    includes {
//        actor = ["*"]
//        trace = ["*"]
//        dispatcher = ["*"]
//    }
//
//    simple-metric-key-generator {
//        # Application prefix for all metrics pushed to StatsD. The default namespacing scheme for metrics follows
//        # this pattern:
//        #    application.host.entity.entity-name.metric-name
//        application = "knora-api"
//    }
//}
//kamon.newrelic {
//    app-name = "knora-api"
//    license-key = "f4794f4107b755c3c94c1d271ecc246f74469830"
//}
